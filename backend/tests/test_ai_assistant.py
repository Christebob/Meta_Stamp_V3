"""
Comprehensive test suite for AI Assistant Service.

This module provides extensive testing coverage for the LangChain-based AI assistant
including multi-provider support (OpenAI GPT-4/5, Anthropic Claude, Google Gemini,
local models), provider switching via environment configuration, tool calling for
fingerprint and analytics queries, streaming responses via Server-Sent Events,
and conversation context management in Redis with 1-hour TTL.

Based on Agent Action Plan sections 0.3, 0.4, 0.5, 0.6, 0.8, and 0.10.
"""

import pytest
import asyncio
import json
import time
from typing import AsyncIterator, Dict, Any, List, Optional
from unittest.mock import Mock, AsyncMock, patch, MagicMock
from datetime import datetime, timedelta

# External imports
from langchain_core.messages import AIMessage, HumanMessage, SystemMessage

# Internal imports - ONLY from depends_on_files
from app.services.ai_assistant_service import (
    AIAssistantService,
    lookup_fingerprint,
    query_analytics,
)
from app.api.v1.assistant import router
from app.config import Settings
from app.core.redis_client import get_redis_client, RedisClient
from app.core.database import get_db_client, DatabaseClient


# =============================================================================
# TEST FIXTURES
# =============================================================================


@pytest.fixture
def mock_settings() -> Settings:
    """Create mock Settings with test API keys and configuration."""
    settings = MagicMock(spec=Settings)
    settings.openai_api_key = "test-openai-key"
    settings.anthropic_api_key = "test-anthropic-key"
    settings.google_api_key = "test-google-key"
    settings.default_ai_provider = "openai"
    settings.default_ai_model = "gpt-4"
    settings.secret_key = "test-secret-key-for-jwt-signing"
    settings.jwt_algorithm = "HS256"
    settings.jwt_expiration_hours = 24
    settings.redis_url = "redis://localhost:6379/1"
    settings.mongodb_uri = "mongodb://localhost:27017/test_metastamp"
    settings.is_auth0_enabled = False
    return settings


@pytest.fixture
def mock_settings_no_openai() -> Settings:
    """Settings without OpenAI API key for fallback testing."""
    settings = MagicMock(spec=Settings)
    settings.openai_api_key = None
    settings.anthropic_api_key = "test-anthropic-key"
    settings.google_api_key = "test-google-key"
    settings.default_ai_provider = "openai"
    settings.default_ai_model = "gpt-4"
    settings.secret_key = "test-secret-key"
    settings.jwt_algorithm = "HS256"
    settings.jwt_expiration_hours = 24
    settings.redis_url = "redis://localhost:6379/1"
    settings.mongodb_uri = "mongodb://localhost:27017/test_metastamp"
    settings.is_auth0_enabled = False
    return settings


@pytest.fixture
def mock_redis() -> AsyncMock:
    """Create mock Redis client for context storage testing."""
    mock = AsyncMock(spec=RedisClient)
    mock.get = AsyncMock(return_value=None)
    mock.set = AsyncMock(return_value=True)
    mock.delete = AsyncMock(return_value=True)
    mock.exists = AsyncMock(return_value=False)
    mock.get_json = AsyncMock(return_value=None)
    mock.set_json = AsyncMock(return_value=True)
    mock.client = AsyncMock()
    mock.client.get = AsyncMock(return_value=None)
    mock.client.set = AsyncMock(return_value=True)
    mock.client.setex = AsyncMock(return_value=True)
    mock.client.delete = AsyncMock(return_value=1)
    return mock


@pytest.fixture
def mock_db() -> AsyncMock:
    """Create mock MongoDB client for tool data testing."""
    mock = AsyncMock(spec=DatabaseClient)
    mock.get_fingerprints_collection = MagicMock()
    mock.get_analytics_collection = MagicMock()
    mock.get_assets_collection = MagicMock()
    mock.get_users_collection = MagicMock()
    
    # Configure fingerprints collection mock
    fingerprints_collection = AsyncMock()
    fingerprints_collection.find_one = AsyncMock(return_value=None)
    mock.get_fingerprints_collection.return_value = fingerprints_collection
    
    # Configure analytics collection mock
    analytics_collection = AsyncMock()
    analytics_collection.find_one = AsyncMock(return_value=None)
    analytics_collection.find = MagicMock()
    mock.get_analytics_collection.return_value = analytics_collection
    
    return mock


@pytest.fixture
def mock_langchain() -> AsyncMock:
    """Create mock LangChain chat model for assistant testing."""
    mock = AsyncMock()
    mock.invoke = AsyncMock(return_value=AIMessage(content="Test response from AI assistant"))
    mock.ainvoke = AsyncMock(return_value=AIMessage(content="Test async response from AI assistant"))
    mock.bind_tools = MagicMock(return_value=mock)
    
    # Configure streaming mock
    async def mock_astream(*args, **kwargs):
        """Mock async stream generator."""
        chunks = ["Test ", "streaming ", "response ", "from ", "assistant."]
        for chunk in chunks:
            mock_chunk = MagicMock()
            mock_chunk.content = chunk
            yield mock_chunk
    
    mock.astream = mock_astream
    return mock


@pytest.fixture
def mock_langchain_with_tools() -> AsyncMock:
    """Create mock LangChain model with tool calling capability."""
    mock = AsyncMock()
    
    # Response with tool call
    tool_call_response = AIMessage(
        content="",
        tool_calls=[{
            "id": "call_123",
            "name": "lookup_fingerprint",
            "args": {"asset_id": "test-asset-123"}
        }]
    )
    
    mock.ainvoke = AsyncMock(return_value=tool_call_response)
    mock.bind_tools = MagicMock(return_value=mock)
    return mock


@pytest.fixture
def mock_conversation_context() -> List[Dict[str, Any]]:
    """Sample conversation history for testing."""
    return [
        {"role": "user", "content": "What is my asset's fingerprint?"},
        {"role": "assistant", "content": "I can help you with that. Let me look up your asset."},
        {"role": "user", "content": "The asset ID is test-asset-123"},
        {"role": "assistant", "content": "I found your asset. The fingerprint shows..."},
    ]


@pytest.fixture
def test_user() -> Dict[str, Any]:
    """Sample user data for authentication testing."""
    return {
        "_id": "test-user-id-12345",
        "email": "testuser@example.com",
        "auth0_id": None,
        "created_at": datetime.utcnow(),
        "last_login": datetime.utcnow()
    }


@pytest.fixture
def test_jwt_token(mock_settings: Settings, test_user: Dict[str, Any]) -> str:
    """Generate test JWT token for authentication."""
    from jose import jwt
    payload = {
        "sub": test_user["_id"],
        "email": test_user["email"],
        "exp": datetime.utcnow() + timedelta(hours=24),
        "iat": datetime.utcnow(),
        "type": "local"
    }
    return jwt.encode(payload, mock_settings.secret_key, algorithm="HS256")


@pytest.fixture
def mock_auth(test_user: Dict[str, Any], test_jwt_token: str) -> Dict[str, Any]:
    """Create authentication fixture with user, token, and headers."""
    return {
        "user": test_user,
        "token": test_jwt_token,
        "headers": {"Authorization": f"Bearer {test_jwt_token}"}
    }


@pytest.fixture
def test_fingerprint_data() -> Dict[str, Any]:
    """Sample fingerprint data for tool testing."""
    return {
        "_id": "fingerprint-id-456",
        "asset_id": "test-asset-123",
        "perceptual_hashes": {
            "phash": "abcd1234efgh5678",
            "ahash": "1234abcd5678efgh",
            "dhash": "5678efgh1234abcd"
        },
        "embeddings": [0.1, 0.2, 0.3, 0.4, 0.5] * 256,
        "spectral_data": None,
        "metadata": {
            "width": 1920,
            "height": 1080,
            "format": "PNG"
        },
        "created_at": datetime.utcnow().isoformat()
    }


@pytest.fixture
def test_analytics_data() -> Dict[str, Any]:
    """Sample analytics data for tool testing."""
    return {
        "_id": "analytics-id-789",
        "asset_id": "test-asset-123",
        "user_id": "test-user-id-12345",
        "model_earnings": 10000.00,
        "training_contribution_score": 75,
        "usage_exposure_score": 60,
        "equity_factor": 0.25,
        "calculated_value": 1125.00,
        "formula_breakdown": {
            "contribution_factor": 0.75,
            "exposure_factor": 0.60,
            "raw_value": 4500.00,
            "final_value": 1125.00
        },
        "created_at": datetime.utcnow().isoformat()
    }


# =============================================================================
# LANGCHAIN PROVIDER INITIALIZATION TESTS
# =============================================================================


class TestProviderInitialization:
    """Tests for LangChain multi-provider initialization."""
    
    @pytest.mark.asyncio
    async def test_init_chat_model_openai(self, mock_settings: Settings):
        """Test OpenAI GPT-4 initialization."""
        with patch("app.services.ai_assistant_service.init_chat_model") as mock_init:
            mock_model = MagicMock()
            mock_init.return_value = mock_model
            
            service = AIAssistantService(
                settings=mock_settings,
                redis_client=AsyncMock(),
                db_client=AsyncMock()
            )
            
            # Verify provider initialization was called with openai
            assert service is not None
    
    @pytest.mark.asyncio
    async def test_init_chat_model_anthropic(self, mock_settings: Settings):
        """Test Anthropic Claude initialization."""
        mock_settings.default_ai_provider = "anthropic"
        mock_settings.default_ai_model = "claude-3-5-sonnet"
        
        with patch("app.services.ai_assistant_service.init_chat_model") as mock_init:
            mock_model = MagicMock()
            mock_init.return_value = mock_model
            
            service = AIAssistantService(
                settings=mock_settings,
                redis_client=AsyncMock(),
                db_client=AsyncMock()
            )
            
            assert service is not None
    
    @pytest.mark.asyncio
    async def test_init_chat_model_google(self, mock_settings: Settings):
        """Test Google Gemini initialization."""
        mock_settings.default_ai_provider = "google"
        mock_settings.default_ai_model = "gemini-2.0-flash"
        
        with patch("app.services.ai_assistant_service.init_chat_model") as mock_init:
            mock_model = MagicMock()
            mock_init.return_value = mock_model
            
            service = AIAssistantService(
                settings=mock_settings,
                redis_client=AsyncMock(),
                db_client=AsyncMock()
            )
            
            assert service is not None
    
    @pytest.mark.asyncio
    async def test_init_chat_model_local(self, mock_settings: Settings):
        """Test local model initialization."""
        mock_settings.default_ai_provider = "local"
        mock_settings.default_ai_model = "llama-3"
        
        with patch("app.services.ai_assistant_service.init_chat_model") as mock_init:
            mock_model = MagicMock()
            mock_init.return_value = mock_model
            
            service = AIAssistantService(
                settings=mock_settings,
                redis_client=AsyncMock(),
                db_client=AsyncMock()
            )
            
            assert service is not None
    
    @pytest.mark.asyncio
    async def test_init_chat_model_invalid_provider(self, mock_settings: Settings):
        """Verify error for unsupported provider."""
        mock_settings.default_ai_provider = "unsupported_provider"
        mock_settings.default_ai_model = "some-model"
        
        with patch("app.services.ai_assistant_service.init_chat_model") as mock_init:
            mock_init.side_effect = ValueError("Unsupported provider")
            
            with pytest.raises(ValueError) as exc_info:
                AIAssistantService(
                    settings=mock_settings,
                    redis_client=AsyncMock(),
                    db_client=AsyncMock()
                )
            
            assert "Unsupported" in str(exc_info.value) or "provider" in str(exc_info.value).lower()


# =============================================================================
# PROVIDER SWITCHING TESTS
# =============================================================================


class TestProviderSwitching:
    """Tests for runtime provider switching and configuration."""
    
    @pytest.mark.asyncio
    async def test_switch_provider_openai_to_anthropic(self, mock_settings: Settings):
        """Test runtime provider change from OpenAI to Anthropic."""
        with patch("app.services.ai_assistant_service.init_chat_model") as mock_init:
            mock_model = MagicMock()
            mock_init.return_value = mock_model
            
            service = AIAssistantService(
                settings=mock_settings,
                redis_client=AsyncMock(),
                db_client=AsyncMock()
            )
            
            # Switch to Anthropic
            service._init_model(provider="anthropic", model="claude-3-5-sonnet")
            
            # Verify the model was re-initialized
            assert mock_init.call_count >= 1
    
    @pytest.mark.asyncio
    async def test_switch_provider_via_environment(self, mock_settings: Settings):
        """Test environment variable switching."""
        original_provider = mock_settings.default_ai_provider
        
        # Change provider via settings
        mock_settings.default_ai_provider = "google"
        mock_settings.default_ai_model = "gemini-2.0-flash"
        
        with patch("app.services.ai_assistant_service.init_chat_model") as mock_init:
            mock_model = MagicMock()
            mock_init.return_value = mock_model
            
            service = AIAssistantService(
                settings=mock_settings,
                redis_client=AsyncMock(),
                db_client=AsyncMock()
            )
            
            assert service is not None
        
        # Restore original
        mock_settings.default_ai_provider = original_provider
    
    @pytest.mark.asyncio
    async def test_provider_config_from_settings(self, mock_settings: Settings):
        """Verify settings properly loaded for provider configuration."""
        assert mock_settings.openai_api_key is not None
        assert mock_settings.anthropic_api_key is not None
        assert mock_settings.google_api_key is not None
        assert mock_settings.default_ai_provider == "openai"
        assert mock_settings.default_ai_model == "gpt-4"
    
    @pytest.mark.asyncio
    async def test_provider_api_key_validation(self, mock_settings_no_openai: Settings):
        """Verify missing API key raises appropriate error."""
        with patch("app.services.ai_assistant_service.init_chat_model") as mock_init:
            mock_init.side_effect = ValueError("API key not configured")
            
            with pytest.raises(ValueError) as exc_info:
                AIAssistantService(
                    settings=mock_settings_no_openai,
                    redis_client=AsyncMock(),
                    db_client=AsyncMock()
                )
            
            assert "API key" in str(exc_info.value) or "not configured" in str(exc_info.value)


# =============================================================================
# TOOL CALLING FUNCTIONALITY TESTS
# =============================================================================


class TestToolCalling:
    """Tests for LangChain tool calling functionality."""
    
    @pytest.mark.asyncio
    async def test_tool_call_fingerprint_lookup(
        self, 
        mock_db: AsyncMock,
        test_fingerprint_data: Dict[str, Any]
    ):
        """Test tool queries fingerprint by asset_id."""
        # Configure mock to return fingerprint data
        fingerprints_collection = mock_db.get_fingerprints_collection.return_value
        fingerprints_collection.find_one = AsyncMock(return_value=test_fingerprint_data)
        
        # Call the tool function
        result = await lookup_fingerprint(
            asset_id="test-asset-123",
            db_client=mock_db
        )
        
        # Verify the query was made
        fingerprints_collection.find_one.assert_called_once()
        
        # Verify result contains fingerprint data
        assert result is not None
        assert "perceptual_hashes" in result or "asset_id" in str(result)
    
    @pytest.mark.asyncio
    async def test_tool_call_analytics_query(
        self,
        mock_db: AsyncMock,
        test_analytics_data: Dict[str, Any]
    ):
        """Test tool queries analytics data."""
        # Configure mock to return analytics data
        analytics_collection = mock_db.get_analytics_collection.return_value
        analytics_collection.find_one = AsyncMock(return_value=test_analytics_data)
        
        # Call the tool function
        result = await query_analytics(
            asset_id="test-asset-123",
            db_client=mock_db
        )
        
        # Verify the query was made
        analytics_collection.find_one.assert_called_once()
        
        # Verify result contains analytics data
        assert result is not None
    
    @pytest.mark.asyncio
    async def test_bind_tools_to_model(self, mock_langchain: AsyncMock):
        """Test tools properly bound to chat model."""
        # Bind tools to the mock model
        tools = [lookup_fingerprint, query_analytics]
        bound_model = mock_langchain.bind_tools(tools)
        
        # Verify bind_tools was called
        mock_langchain.bind_tools.assert_called_once_with(tools)
        
        # Verify model is returned
        assert bound_model is not None
    
    @pytest.mark.asyncio
    async def test_tool_execution_from_assistant(
        self,
        mock_settings: Settings,
        mock_redis: AsyncMock,
        mock_db: AsyncMock,
        test_fingerprint_data: Dict[str, Any]
    ):
        """Test assistant invokes tools during conversation."""
        # Setup fingerprint data
        fingerprints_collection = mock_db.get_fingerprints_collection.return_value
        fingerprints_collection.find_one = AsyncMock(return_value=test_fingerprint_data)
        
        with patch("app.services.ai_assistant_service.init_chat_model") as mock_init:
            # Create a model that returns tool call
            mock_model = AsyncMock()
            mock_model.ainvoke = AsyncMock(return_value=AIMessage(
                content="Let me look up that fingerprint for you.",
                tool_calls=[{
                    "id": "call_abc123",
                    "name": "lookup_fingerprint",
                    "args": {"asset_id": "test-asset-123"}
                }]
            ))
            mock_model.bind_tools = MagicMock(return_value=mock_model)
            mock_init.return_value = mock_model
            
            service = AIAssistantService(
                settings=mock_settings,
                redis_client=mock_redis,
                db_client=mock_db
            )
            
            # Send message requesting fingerprint lookup
            response = await service.send_message(
                user_id="test-user-id",
                message="What are the fingerprint hashes for asset test-asset-123?",
                conversation_id="conv-123"
            )
            
            assert response is not None
    
    @pytest.mark.asyncio
    async def test_tool_call_error_handling(self, mock_db: AsyncMock):
        """Test graceful handling when tool fails."""
        # Configure mock to raise exception
        fingerprints_collection = mock_db.get_fingerprints_collection.return_value
        fingerprints_collection.find_one = AsyncMock(
            side_effect=Exception("Database connection failed")
        )
        
        # Call the tool and expect graceful error handling
        try:
            result = await lookup_fingerprint(
                asset_id="test-asset-123",
                db_client=mock_db
            )
            # If no exception, result should indicate error
            assert result is None or "error" in str(result).lower()
        except Exception as e:
            # Exception handling is also valid behavior
            assert "Database" in str(e) or "connection" in str(e).lower()
    
    @pytest.mark.asyncio
    async def test_tool_results_in_conversation(
        self,
        mock_settings: Settings,
        mock_redis: AsyncMock,
        mock_db: AsyncMock
    ):
        """Verify tool results included in conversation context."""
        with patch("app.services.ai_assistant_service.init_chat_model") as mock_init:
            mock_model = AsyncMock()
            mock_model.ainvoke = AsyncMock(return_value=AIMessage(
                content="The fingerprint hash is abcd1234."
            ))
            mock_model.bind_tools = MagicMock(return_value=mock_model)
            mock_init.return_value = mock_model
            
            service = AIAssistantService(
                settings=mock_settings,
                redis_client=mock_redis,
                db_client=mock_db
            )
            
            # Get initial context
            response = await service.send_message(
                user_id="test-user",
                message="Show me the fingerprint",
                conversation_id="conv-test"
            )
            
            # Verify context was saved (set_json should be called)
            assert mock_redis.set_json.called or mock_redis.client.setex.called


# =============================================================================
# STREAMING RESPONSE TESTS
# =============================================================================


class TestStreamingResponses:
    """Tests for streaming response functionality via Server-Sent Events."""
    
    @pytest.mark.asyncio
    async def test_streaming_response_generation(
        self,
        mock_settings: Settings,
        mock_redis: AsyncMock,
        mock_db: AsyncMock
    ):
        """Test streaming token generation."""
        with patch("app.services.ai_assistant_service.init_chat_model") as mock_init:
            mock_model = AsyncMock()
            
            # Create async generator for streaming
            async def mock_stream(*args, **kwargs):
                chunks = ["Hello", " there", ", how", " can", " I help?"]
                for chunk in chunks:
                    mock_chunk = MagicMock()
                    mock_chunk.content = chunk
                    yield mock_chunk
            
            mock_model.astream = mock_stream
            mock_model.bind_tools = MagicMock(return_value=mock_model)
            mock_init.return_value = mock_model
            
            service = AIAssistantService(
                settings=mock_settings,
                redis_client=mock_redis,
                db_client=mock_db
            )
            
            # Collect streamed response
            collected_chunks = []
            async for chunk in service.send_message_stream(
                user_id="test-user",
                message="Hello",
                conversation_id="conv-stream"
            ):
                collected_chunks.append(chunk)
            
            # Verify we got chunks
            assert len(collected_chunks) > 0
    
    @pytest.mark.asyncio
    async def test_streaming_response_format(self):
        """Verify Server-Sent Events format."""
        # SSE format should be: data: {content}\n\n
        test_content = "Test message content"
        sse_format = f"data: {json.dumps({'content': test_content})}\n\n"
        
        # Verify format structure
        assert sse_format.startswith("data: ")
        assert sse_format.endswith("\n\n")
        
        # Verify JSON content
        json_part = sse_format.replace("data: ", "").strip()
        parsed = json.loads(json_part)
        assert parsed["content"] == test_content
    
    @pytest.mark.asyncio
    async def test_streaming_partial_updates(
        self,
        mock_settings: Settings,
        mock_redis: AsyncMock,
        mock_db: AsyncMock
    ):
        """Test incremental message updates during streaming."""
        with patch("app.services.ai_assistant_service.init_chat_model") as mock_init:
            mock_model = AsyncMock()
            
            # Tokens that form a complete sentence
            tokens = ["The", " answer", " is", " 42", "."]
            
            async def mock_stream(*args, **kwargs):
                for token in tokens:
                    mock_chunk = MagicMock()
                    mock_chunk.content = token
                    yield mock_chunk
            
            mock_model.astream = mock_stream
            mock_model.bind_tools = MagicMock(return_value=mock_model)
            mock_init.return_value = mock_model
            
            service = AIAssistantService(
                settings=mock_settings,
                redis_client=mock_redis,
                db_client=mock_db
            )
            
            # Collect and verify incremental updates
            received_tokens = []
            async for chunk in service.send_message_stream(
                user_id="test-user",
                message="What is the answer?",
                conversation_id="conv-partial"
            ):
                received_tokens.append(chunk)
            
            # Verify each token was received
            assert len(received_tokens) == len(tokens)
    
    @pytest.mark.asyncio
    async def test_streaming_error_mid_stream(
        self,
        mock_settings: Settings,
        mock_redis: AsyncMock,
        mock_db: AsyncMock
    ):
        """Test error handling during streaming."""
        with patch("app.services.ai_assistant_service.init_chat_model") as mock_init:
            mock_model = AsyncMock()
            
            # Stream that fails midway
            async def mock_stream_with_error(*args, **kwargs):
                yield MagicMock(content="Starting")
                yield MagicMock(content=" response")
                raise Exception("Connection lost mid-stream")
            
            mock_model.astream = mock_stream_with_error
            mock_model.bind_tools = MagicMock(return_value=mock_model)
            mock_init.return_value = mock_model
            
            service = AIAssistantService(
                settings=mock_settings,
                redis_client=mock_redis,
                db_client=mock_db
            )
            
            # Attempt to stream and handle error gracefully
            received_chunks = []
            error_occurred = False
            
            try:
                async for chunk in service.send_message_stream(
                    user_id="test-user",
                    message="Test message",
                    conversation_id="conv-error"
                ):
                    received_chunks.append(chunk)
            except Exception:
                error_occurred = True
            
            # Either error was raised or service handled it gracefully
            assert error_occurred or len(received_chunks) >= 2
    
    @pytest.mark.asyncio
    async def test_streaming_completion_marker(self):
        """Verify stream ends with proper completion marker."""
        # SSE completion marker
        completion_marker = "data: [DONE]\n\n"
        
        assert completion_marker.startswith("data: ")
        assert "[DONE]" in completion_marker
        assert completion_marker.endswith("\n\n")


# =============================================================================
# CONVERSATION CONTEXT MANAGEMENT TESTS
# =============================================================================


class TestConversationContext:
    """Tests for Redis-based conversation context management."""
    
    @pytest.mark.asyncio
    async def test_store_conversation_redis(
        self,
        mock_settings: Settings,
        mock_redis: AsyncMock,
        mock_db: AsyncMock
    ):
        """Test conversation stored with 1-hour TTL."""
        with patch("app.services.ai_assistant_service.init_chat_model") as mock_init:
            mock_model = AsyncMock()
            mock_model.ainvoke = AsyncMock(return_value=AIMessage(content="Response"))
            mock_model.bind_tools = MagicMock(return_value=mock_model)
            mock_init.return_value = mock_model
            
            service = AIAssistantService(
                settings=mock_settings,
                redis_client=mock_redis,
                db_client=mock_db
            )
            
            await service.send_message(
                user_id="test-user-context",
                message="Store this message",
                conversation_id="conv-store"
            )
            
            # Verify Redis was called to store context
            assert mock_redis.set_json.called or mock_redis.client.setex.called
    
    @pytest.mark.asyncio
    async def test_retrieve_conversation_context(
        self,
        mock_settings: Settings,
        mock_redis: AsyncMock,
        mock_db: AsyncMock,
        mock_conversation_context: List[Dict[str, Any]]
    ):
        """Test context retrieval from Redis."""
        # Setup mock to return existing context
        mock_redis.get_json = AsyncMock(return_value=mock_conversation_context)
        
        with patch("app.services.ai_assistant_service.init_chat_model") as mock_init:
            mock_model = AsyncMock()
            mock_model.ainvoke = AsyncMock(return_value=AIMessage(content="Continued response"))
            mock_model.bind_tools = MagicMock(return_value=mock_model)
            mock_init.return_value = mock_model
            
            service = AIAssistantService(
                settings=mock_settings,
                redis_client=mock_redis,
                db_client=mock_db
            )
            
            # Send message which should retrieve existing context
            await service.send_message(
                user_id="test-user",
                message="Continue our conversation",
                conversation_id="conv-retrieve"
            )
            
            # Verify context was retrieved
            mock_redis.get_json.assert_called()
    
    @pytest.mark.asyncio
    async def test_context_includes_message_history(
        self,
        mock_settings: Settings,
        mock_redis: AsyncMock,
        mock_db: AsyncMock
    ):
        """Verify all messages stored in context."""
        stored_context = None
        
        async def capture_set_json(key, value, ttl=None):
            nonlocal stored_context
            stored_context = value
            return True
        
        mock_redis.set_json = AsyncMock(side_effect=capture_set_json)
        
        with patch("app.services.ai_assistant_service.init_chat_model") as mock_init:
            mock_model = AsyncMock()
            mock_model.ainvoke = AsyncMock(return_value=AIMessage(content="Test response"))
            mock_model.bind_tools = MagicMock(return_value=mock_model)
            mock_init.return_value = mock_model
            
            service = AIAssistantService(
                settings=mock_settings,
                redis_client=mock_redis,
                db_client=mock_db
            )
            
            # Send first message
            await service.send_message(
                user_id="test-user",
                message="First message",
                conversation_id="conv-history"
            )
            
            # Verify context contains messages
            if stored_context:
                assert isinstance(stored_context, (list, dict))
    
    @pytest.mark.asyncio
    async def test_context_ttl_one_hour(
        self,
        mock_settings: Settings,
        mock_redis: AsyncMock,
        mock_db: AsyncMock
    ):
        """Verify 3600-second (1 hour) TTL for conversation context."""
        captured_ttl = None
        
        async def capture_setex(key, ttl, value):
            nonlocal captured_ttl
            captured_ttl = ttl
            return True
        
        mock_redis.client.setex = AsyncMock(side_effect=capture_setex)
        
        with patch("app.services.ai_assistant_service.init_chat_model") as mock_init:
            mock_model = AsyncMock()
            mock_model.ainvoke = AsyncMock(return_value=AIMessage(content="Response"))
            mock_model.bind_tools = MagicMock(return_value=mock_model)
            mock_init.return_value = mock_model
            
            service = AIAssistantService(
                settings=mock_settings,
                redis_client=mock_redis,
                db_client=mock_db
            )
            
            await service.send_message(
                user_id="test-user",
                message="Test TTL",
                conversation_id="conv-ttl"
            )
            
            # Verify TTL is 1 hour (3600 seconds)
            if captured_ttl is not None:
                assert captured_ttl == 3600
    
    @pytest.mark.asyncio
    async def test_conversation_continues_across_requests(
        self,
        mock_settings: Settings,
        mock_redis: AsyncMock,
        mock_db: AsyncMock
    ):
        """Test multi-turn conversation persists across requests."""
        conversation_history = []
        
        async def mock_get_json(key):
            return conversation_history if conversation_history else None
        
        async def mock_set_json(key, value, ttl=None):
            nonlocal conversation_history
            conversation_history = value
            return True
        
        mock_redis.get_json = AsyncMock(side_effect=mock_get_json)
        mock_redis.set_json = AsyncMock(side_effect=mock_set_json)
        
        with patch("app.services.ai_assistant_service.init_chat_model") as mock_init:
            mock_model = AsyncMock()
            call_count = [0]
            
            async def multi_response(*args, **kwargs):
                call_count[0] += 1
                return AIMessage(content=f"Response {call_count[0]}")
            
            mock_model.ainvoke = AsyncMock(side_effect=multi_response)
            mock_model.bind_tools = MagicMock(return_value=mock_model)
            mock_init.return_value = mock_model
            
            service = AIAssistantService(
                settings=mock_settings,
                redis_client=mock_redis,
                db_client=mock_db
            )
            
            # First request
            await service.send_message(
                user_id="test-user",
                message="First turn",
                conversation_id="conv-multi"
            )
            
            # Second request (should have context)
            await service.send_message(
                user_id="test-user",
                message="Second turn",
                conversation_id="conv-multi"
            )
            
            # Verify multiple calls were made
            assert mock_model.ainvoke.call_count == 2
    
    @pytest.mark.asyncio
    async def test_context_expiration(
        self,
        mock_settings: Settings,
        mock_redis: AsyncMock,
        mock_db: AsyncMock
    ):
        """Test behavior when context expires (returns None)."""
        # Mock expired/missing context
        mock_redis.get_json = AsyncMock(return_value=None)
        
        with patch("app.services.ai_assistant_service.init_chat_model") as mock_init:
            mock_model = AsyncMock()
            mock_model.ainvoke = AsyncMock(return_value=AIMessage(content="Fresh start"))
            mock_model.bind_tools = MagicMock(return_value=mock_model)
            mock_init.return_value = mock_model
            
            service = AIAssistantService(
                settings=mock_settings,
                redis_client=mock_redis,
                db_client=mock_db
            )
            
            # Should work fine even without existing context
            response = await service.send_message(
                user_id="test-user",
                message="Message after expiration",
                conversation_id="conv-expired"
            )
            
            assert response is not None


# =============================================================================
# MESSAGE HANDLING TESTS
# =============================================================================


class TestMessageHandling:
    """Tests for message sending and formatting."""
    
    @pytest.mark.asyncio
    async def test_send_message_to_assistant(
        self,
        mock_settings: Settings,
        mock_redis: AsyncMock,
        mock_db: AsyncMock
    ):
        """Test basic message sending."""
        with patch("app.services.ai_assistant_service.init_chat_model") as mock_init:
            mock_model = AsyncMock()
            mock_model.ainvoke = AsyncMock(return_value=AIMessage(
                content="Hello! How can I help you today?"
            ))
            mock_model.bind_tools = MagicMock(return_value=mock_model)
            mock_init.return_value = mock_model
            
            service = AIAssistantService(
                settings=mock_settings,
                redis_client=mock_redis,
                db_client=mock_db
            )
            
            response = await service.send_message(
                user_id="test-user",
                message="Hello assistant",
                conversation_id="conv-basic"
            )
            
            assert response is not None
            assert "Hello" in response or "help" in response.lower()
    
    @pytest.mark.asyncio
    async def test_message_with_context(
        self,
        mock_settings: Settings,
        mock_redis: AsyncMock,
        mock_db: AsyncMock,
        mock_conversation_context: List[Dict[str, Any]]
    ):
        """Test message uses conversation history."""
        mock_redis.get_json = AsyncMock(return_value=mock_conversation_context)
        
        with patch("app.services.ai_assistant_service.init_chat_model") as mock_init:
            mock_model = AsyncMock()
            
            # Capture what's passed to the model
            invoked_messages = []
            
            async def capture_invoke(messages, **kwargs):
                invoked_messages.append(messages)
                return AIMessage(content="Response with context")
            
            mock_model.ainvoke = AsyncMock(side_effect=capture_invoke)
            mock_model.bind_tools = MagicMock(return_value=mock_model)
            mock_init.return_value = mock_model
            
            service = AIAssistantService(
                settings=mock_settings,
                redis_client=mock_redis,
                db_client=mock_db
            )
            
            await service.send_message(
                user_id="test-user",
                message="Continue our chat",
                conversation_id="conv-with-context"
            )
            
            # Model should have been invoked with context
            assert mock_model.ainvoke.called
    
    @pytest.mark.asyncio
    async def test_message_formatting(
        self,
        mock_settings: Settings,
        mock_redis: AsyncMock,
        mock_db: AsyncMock
    ):
        """Verify proper message structure."""
        captured_messages = []
        
        with patch("app.services.ai_assistant_service.init_chat_model") as mock_init:
            mock_model = AsyncMock()
            
            async def capture_invoke(messages, **kwargs):
                captured_messages.extend(messages)
                return AIMessage(content="Formatted response")
            
            mock_model.ainvoke = AsyncMock(side_effect=capture_invoke)
            mock_model.bind_tools = MagicMock(return_value=mock_model)
            mock_init.return_value = mock_model
            
            service = AIAssistantService(
                settings=mock_settings,
                redis_client=mock_redis,
                db_client=mock_db
            )
            
            await service.send_message(
                user_id="test-user",
                message="Test message",
                conversation_id="conv-format"
            )
            
            # Verify messages include HumanMessage
            has_human_message = any(
                isinstance(m, HumanMessage) or 
                (hasattr(m, "type") and m.type == "human")
                for m in captured_messages
            )
            assert has_human_message or len(captured_messages) > 0
    
    @pytest.mark.asyncio
    async def test_system_message_injection(
        self,
        mock_settings: Settings,
        mock_redis: AsyncMock,
        mock_db: AsyncMock
    ):
        """Test system prompt inclusion."""
        captured_messages = []
        
        with patch("app.services.ai_assistant_service.init_chat_model") as mock_init:
            mock_model = AsyncMock()
            
            async def capture_invoke(messages, **kwargs):
                captured_messages.extend(messages)
                return AIMessage(content="Response with system context")
            
            mock_model.ainvoke = AsyncMock(side_effect=capture_invoke)
            mock_model.bind_tools = MagicMock(return_value=mock_model)
            mock_init.return_value = mock_model
            
            service = AIAssistantService(
                settings=mock_settings,
                redis_client=mock_redis,
                db_client=mock_db
            )
            
            await service.send_message(
                user_id="test-user",
                message="Query about assets",
                conversation_id="conv-system"
            )
            
            # Verify system message was included
            has_system_message = any(
                isinstance(m, SystemMessage) or
                (hasattr(m, "type") and m.type == "system")
                for m in captured_messages
            )
            # System message should be present in most implementations
            assert mock_model.ainvoke.called
    
    @pytest.mark.asyncio
    async def test_user_message_validation(self):
        """Test input sanitization."""
        # Test various edge cases
        test_cases = [
            "",  # Empty message
            " " * 100,  # Whitespace only
            "Normal message",  # Valid
            "<script>alert('xss')</script>",  # XSS attempt
            "A" * 10000,  # Very long message
        ]
        
        for message in test_cases:
            # Basic validation - ensure no unhandled exceptions
            cleaned = message.strip()
            # Very long messages should be handled gracefully
            if len(cleaned) > 8000:
                # Message should be truncated or rejected
                assert len(cleaned) > 0  # Just verify it's handleable


# =============================================================================
# ASSISTANT PERSONALITY TESTS
# =============================================================================


class TestAssistantPersonalities:
    """Tests for friendly and legal advisory personality modes."""
    
    @pytest.mark.asyncio
    async def test_friendly_guidance_mode(
        self,
        mock_settings: Settings,
        mock_redis: AsyncMock,
        mock_db: AsyncMock
    ):
        """Test friendly personality responses."""
        with patch("app.services.ai_assistant_service.init_chat_model") as mock_init:
            mock_model = AsyncMock()
            mock_model.ainvoke = AsyncMock(return_value=AIMessage(
                content="Hey there! I'd be happy to help you understand your assets! ðŸ˜Š"
            ))
            mock_model.bind_tools = MagicMock(return_value=mock_model)
            mock_init.return_value = mock_model
            
            service = AIAssistantService(
                settings=mock_settings,
                redis_client=mock_redis,
                db_client=mock_db
            )
            
            response = await service.send_message(
                user_id="test-user",
                message="Help me understand my assets",
                conversation_id="conv-friendly",
                personality="friendly"
            )
            
            assert response is not None
    
    @pytest.mark.asyncio
    async def test_legal_advisory_mode(
        self,
        mock_settings: Settings,
        mock_redis: AsyncMock,
        mock_db: AsyncMock
    ):
        """Test serious legal personality."""
        with patch("app.services.ai_assistant_service.init_chat_model") as mock_init:
            mock_model = AsyncMock()
            mock_model.ainvoke = AsyncMock(return_value=AIMessage(
                content="Based on my analysis, your intellectual property rights "
                        "in this creative work are protected under applicable copyright law."
            ))
            mock_model.bind_tools = MagicMock(return_value=mock_model)
            mock_init.return_value = mock_model
            
            service = AIAssistantService(
                settings=mock_settings,
                redis_client=mock_redis,
                db_client=mock_db
            )
            
            response = await service.send_message(
                user_id="test-user",
                message="What are my legal rights for this asset?",
                conversation_id="conv-legal",
                personality="legal"
            )
            
            assert response is not None
    
    @pytest.mark.asyncio
    async def test_personality_switch_mid_conversation(
        self,
        mock_settings: Settings,
        mock_redis: AsyncMock,
        mock_db: AsyncMock
    ):
        """Test mode switching mid-conversation."""
        with patch("app.services.ai_assistant_service.init_chat_model") as mock_init:
            mock_model = AsyncMock()
            response_count = [0]
            
            async def switch_response(*args, **kwargs):
                response_count[0] += 1
                if response_count[0] == 1:
                    return AIMessage(content="Friendly response first")
                return AIMessage(content="Now switching to legal advisory mode")
            
            mock_model.ainvoke = AsyncMock(side_effect=switch_response)
            mock_model.bind_tools = MagicMock(return_value=mock_model)
            mock_init.return_value = mock_model
            
            service = AIAssistantService(
                settings=mock_settings,
                redis_client=mock_redis,
                db_client=mock_db
            )
            
            # First message with friendly personality
            response1 = await service.send_message(
                user_id="test-user",
                message="Hello",
                conversation_id="conv-switch",
                personality="friendly"
            )
            
            # Switch to legal personality
            response2 = await service.send_message(
                user_id="test-user",
                message="Now tell me about legal rights",
                conversation_id="conv-switch",
                personality="legal"
            )
            
            assert response1 is not None
            assert response2 is not None


# =============================================================================
# ERROR HANDLING AND RETRY TESTS
# =============================================================================


class TestErrorHandlingAndRetries:
    """Tests for error handling and retry mechanisms."""
    
    @pytest.mark.asyncio
    async def test_provider_api_error(
        self,
        mock_settings: Settings,
        mock_redis: AsyncMock,
        mock_db: AsyncMock
    ):
        """Test handling of API failures."""
        with patch("app.services.ai_assistant_service.init_chat_model") as mock_init:
            mock_model = AsyncMock()
            mock_model.ainvoke = AsyncMock(
                side_effect=Exception("API error: Service unavailable")
            )
            mock_model.bind_tools = MagicMock(return_value=mock_model)
            mock_init.return_value = mock_model
            
            service = AIAssistantService(
                settings=mock_settings,
                redis_client=mock_redis,
                db_client=mock_db
            )
            
            # Should handle error gracefully
            try:
                response = await service.send_message(
                    user_id="test-user",
                    message="Test message",
                    conversation_id="conv-error"
                )
                # If no exception, response should indicate error
                assert response is None or "error" in str(response).lower()
            except Exception as e:
                # Exception is acceptable behavior
                assert "API" in str(e) or "Service" in str(e)
    
    @pytest.mark.asyncio
    async def test_rate_limit_handling(
        self,
        mock_settings: Settings,
        mock_redis: AsyncMock,
        mock_db: AsyncMock
    ):
        """Test exponential backoff on rate limits."""
        with patch("app.services.ai_assistant_service.init_chat_model") as mock_init:
            mock_model = AsyncMock()
            call_count = [0]
            
            async def rate_limited_response(*args, **kwargs):
                call_count[0] += 1
                if call_count[0] <= 2:
                    raise Exception("Rate limit exceeded")
                return AIMessage(content="Success after retry")
            
            mock_model.ainvoke = AsyncMock(side_effect=rate_limited_response)
            mock_model.bind_tools = MagicMock(return_value=mock_model)
            mock_init.return_value = mock_model
            
            service = AIAssistantService(
                settings=mock_settings,
                redis_client=mock_redis,
                db_client=mock_db
            )
            
            # Service might implement retry logic
            try:
                response = await service.send_message(
                    user_id="test-user",
                    message="Test rate limiting",
                    conversation_id="conv-ratelimit"
                )
                # If success, verify response
                if response:
                    assert "Success" in response or call_count[0] > 1
            except Exception:
                # Rate limit exception is also valid
                assert call_count[0] >= 1
    
    @pytest.mark.asyncio
    async def test_timeout_handling(
        self,
        mock_settings: Settings,
        mock_redis: AsyncMock,
        mock_db: AsyncMock
    ):
        """Test request timeout handling."""
        with patch("app.services.ai_assistant_service.init_chat_model") as mock_init:
            mock_model = AsyncMock()
            
            async def slow_response(*args, **kwargs):
                await asyncio.sleep(0.5)  # Simulate slow response
                return AIMessage(content="Eventually responded")
            
            mock_model.ainvoke = AsyncMock(side_effect=slow_response)
            mock_model.bind_tools = MagicMock(return_value=mock_model)
            mock_init.return_value = mock_model
            
            service = AIAssistantService(
                settings=mock_settings,
                redis_client=mock_redis,
                db_client=mock_db
            )
            
            start_time = time.time()
            
            try:
                response = await asyncio.wait_for(
                    service.send_message(
                        user_id="test-user",
                        message="Test timeout",
                        conversation_id="conv-timeout"
                    ),
                    timeout=2.0  # 2 second timeout for test
                )
                elapsed = time.time() - start_time
                assert elapsed < 2.0  # Should complete within timeout
            except asyncio.TimeoutError:
                # Timeout is expected if slow
                pass
    
    @pytest.mark.asyncio
    async def test_fallback_to_alternate_provider(
        self,
        mock_settings: Settings,
        mock_redis: AsyncMock,
        mock_db: AsyncMock
    ):
        """Test provider fallback when primary fails."""
        with patch("app.services.ai_assistant_service.init_chat_model") as mock_init:
            call_count = [0]
            
            def create_model(*args, **kwargs):
                call_count[0] += 1
                if call_count[0] == 1:
                    raise ValueError("OpenAI API key invalid")
                mock_model = AsyncMock()
                mock_model.ainvoke = AsyncMock(return_value=AIMessage(
                    content="Response from fallback provider"
                ))
                mock_model.bind_tools = MagicMock(return_value=mock_model)
                return mock_model
            
            mock_init.side_effect = create_model
            
            # Service might try to initialize with primary, then fallback
            try:
                service = AIAssistantService(
                    settings=mock_settings,
                    redis_client=mock_redis,
                    db_client=mock_db
                )
                
                # If fallback succeeded, service should work
                if service:
                    response = await service.send_message(
                        user_id="test-user",
                        message="Test fallback",
                        conversation_id="conv-fallback"
                    )
            except ValueError:
                # Fallback not implemented is also valid
                assert call_count[0] >= 1


# =============================================================================
# API ENDPOINT INTEGRATION TESTS
# =============================================================================


class TestAPIEndpointIntegration:
    """Tests for API endpoint integration using TestClient."""
    
    @pytest.mark.asyncio
    async def test_assistant_ask_endpoint(
        self,
        mock_settings: Settings,
        mock_redis: AsyncMock,
        mock_db: AsyncMock,
        mock_auth: Dict[str, Any]
    ):
        """Test POST /api/v1/assistant/ask endpoint."""
        from fastapi.testclient import TestClient
        from app.main import app
        
        with patch("app.services.ai_assistant_service.init_chat_model") as mock_init:
            mock_model = AsyncMock()
            mock_model.ainvoke = AsyncMock(return_value=AIMessage(
                content="Test endpoint response"
            ))
            mock_model.bind_tools = MagicMock(return_value=mock_model)
            mock_init.return_value = mock_model
            
            with patch("app.core.redis_client.get_redis_client", return_value=mock_redis):
                with patch("app.core.database.get_db_client", return_value=mock_db):
                    with patch("app.core.auth.get_current_user") as mock_get_user:
                        mock_get_user.return_value = mock_auth["user"]
                        
                        client = TestClient(app)
                        response = client.post(
                            "/api/v1/assistant/ask",
                            json={
                                "message": "Hello assistant",
                                "conversation_id": "test-conv-123"
                            },
                            headers=mock_auth["headers"]
                        )
                        
                        # Should be 200 or streaming response
                        assert response.status_code in [200, 422, 401]
    
    def test_endpoint_requires_authentication(self):
        """Verify 401 without token."""
        from fastapi.testclient import TestClient
        from app.main import app
        
        client = TestClient(app)
        response = client.post(
            "/api/v1/assistant/ask",
            json={
                "message": "Unauthorized request",
                "conversation_id": "test-conv"
            }
        )
        
        # Should require authentication
        assert response.status_code in [401, 403, 422]
    
    @pytest.mark.asyncio
    async def test_endpoint_streaming_response(
        self,
        mock_settings: Settings,
        mock_redis: AsyncMock,
        mock_db: AsyncMock,
        mock_auth: Dict[str, Any]
    ):
        """Verify streaming response format."""
        from fastapi.testclient import TestClient
        from app.main import app
        
        with patch("app.services.ai_assistant_service.init_chat_model") as mock_init:
            mock_model = AsyncMock()
            
            async def mock_stream(*args, **kwargs):
                for chunk in ["Hello", " World"]:
                    mock_chunk = MagicMock()
                    mock_chunk.content = chunk
                    yield mock_chunk
            
            mock_model.astream = mock_stream
            mock_model.bind_tools = MagicMock(return_value=mock_model)
            mock_init.return_value = mock_model
            
            with patch("app.core.redis_client.get_redis_client", return_value=mock_redis):
                with patch("app.core.database.get_db_client", return_value=mock_db):
                    with patch("app.core.auth.get_current_user") as mock_get_user:
                        mock_get_user.return_value = mock_auth["user"]
                        
                        client = TestClient(app)
                        response = client.post(
                            "/api/v1/assistant/ask",
                            json={
                                "message": "Stream test",
                                "conversation_id": "stream-conv",
                                "stream": True
                            },
                            headers=mock_auth["headers"]
                        )
                        
                        # Check response status
                        assert response.status_code in [200, 422, 401]
    
    @pytest.mark.asyncio
    async def test_endpoint_conversation_id(
        self,
        mock_settings: Settings,
        mock_redis: AsyncMock,
        mock_db: AsyncMock,
        mock_auth: Dict[str, Any]
    ):
        """Test conversation ID handling."""
        from fastapi.testclient import TestClient
        from app.main import app
        
        with patch("app.services.ai_assistant_service.init_chat_model") as mock_init:
            mock_model = AsyncMock()
            mock_model.ainvoke = AsyncMock(return_value=AIMessage(
                content="Response with conversation tracking"
            ))
            mock_model.bind_tools = MagicMock(return_value=mock_model)
            mock_init.return_value = mock_model
            
            with patch("app.core.redis_client.get_redis_client", return_value=mock_redis):
                with patch("app.core.database.get_db_client", return_value=mock_db):
                    with patch("app.core.auth.get_current_user") as mock_get_user:
                        mock_get_user.return_value = mock_auth["user"]
                        
                        client = TestClient(app)
                        
                        # Without conversation_id (should generate one)
                        response1 = client.post(
                            "/api/v1/assistant/ask",
                            json={"message": "First message"},
                            headers=mock_auth["headers"]
                        )
                        
                        # With explicit conversation_id
                        response2 = client.post(
                            "/api/v1/assistant/ask",
                            json={
                                "message": "Second message",
                                "conversation_id": "explicit-conv-id"
                            },
                            headers=mock_auth["headers"]
                        )
                        
                        # Both should work
                        assert response1.status_code in [200, 422, 401]
                        assert response2.status_code in [200, 422, 401]
    
    @pytest.mark.asyncio
    async def test_endpoint_validates_input(
        self,
        mock_auth: Dict[str, Any]
    ):
        """Verify 400/422 for invalid inputs."""
        from fastapi.testclient import TestClient
        from app.main import app
        
        with patch("app.core.auth.get_current_user") as mock_get_user:
            mock_get_user.return_value = mock_auth["user"]
            
            client = TestClient(app)
            
            # Empty message
            response = client.post(
                "/api/v1/assistant/ask",
                json={"message": ""},
                headers=mock_auth["headers"]
            )
            
            # Should validate input
            assert response.status_code in [400, 422, 200]


# =============================================================================
# TOOL INTEGRATION WITH SERVICES TESTS
# =============================================================================


class TestToolIntegrationWithServices:
    """Tests for end-to-end tool integration."""
    
    @pytest.mark.asyncio
    async def test_tool_fingerprint_lookup_integration(
        self,
        mock_db: AsyncMock,
        test_fingerprint_data: Dict[str, Any]
    ):
        """Test end-to-end fingerprint query via tool."""
        fingerprints_collection = mock_db.get_fingerprints_collection.return_value
        fingerprints_collection.find_one = AsyncMock(return_value=test_fingerprint_data)
        
        # Execute tool
        result = await lookup_fingerprint(
            asset_id=test_fingerprint_data["asset_id"],
            db_client=mock_db
        )
        
        # Verify database was queried
        fingerprints_collection.find_one.assert_called_once()
        
        # Verify result contains expected data
        assert result is not None
    
    @pytest.mark.asyncio
    async def test_tool_analytics_query_integration(
        self,
        mock_db: AsyncMock,
        test_analytics_data: Dict[str, Any]
    ):
        """Test end-to-end analytics query via tool."""
        analytics_collection = mock_db.get_analytics_collection.return_value
        analytics_collection.find_one = AsyncMock(return_value=test_analytics_data)
        
        # Execute tool
        result = await query_analytics(
            asset_id=test_analytics_data["asset_id"],
            db_client=mock_db
        )
        
        # Verify database was queried
        analytics_collection.find_one.assert_called_once()
        
        # Verify result contains expected data
        assert result is not None
    
    @pytest.mark.asyncio
    async def test_tool_call_authorization(
        self,
        mock_settings: Settings,
        mock_redis: AsyncMock,
        mock_db: AsyncMock,
        mock_auth: Dict[str, Any]
    ):
        """Verify tools respect user permissions."""
        # Configure mock to return data only for authorized user
        fingerprints_collection = mock_db.get_fingerprints_collection.return_value
        
        async def authorized_lookup(query):
            if query.get("user_id") == mock_auth["user"]["_id"]:
                return {"_id": "fp-123", "asset_id": "asset-123"}
            return None
        
        fingerprints_collection.find_one = AsyncMock(side_effect=authorized_lookup)
        
        with patch("app.services.ai_assistant_service.init_chat_model") as mock_init:
            mock_model = AsyncMock()
            mock_model.ainvoke = AsyncMock(return_value=AIMessage(
                content="Checking authorization..."
            ))
            mock_model.bind_tools = MagicMock(return_value=mock_model)
            mock_init.return_value = mock_model
            
            service = AIAssistantService(
                settings=mock_settings,
                redis_client=mock_redis,
                db_client=mock_db
            )
            
            # Service should use tools with proper authorization
            response = await service.send_message(
                user_id=mock_auth["user"]["_id"],
                message="Show my asset fingerprint",
                conversation_id="conv-auth"
            )
            
            assert response is not None
    
    @pytest.mark.asyncio
    async def test_multiple_tool_calls_in_sequence(
        self,
        mock_settings: Settings,
        mock_redis: AsyncMock,
        mock_db: AsyncMock,
        test_fingerprint_data: Dict[str, Any],
        test_analytics_data: Dict[str, Any]
    ):
        """Test chained tool usage (fingerprint then analytics)."""
        fingerprints_collection = mock_db.get_fingerprints_collection.return_value
        fingerprints_collection.find_one = AsyncMock(return_value=test_fingerprint_data)
        
        analytics_collection = mock_db.get_analytics_collection.return_value
        analytics_collection.find_one = AsyncMock(return_value=test_analytics_data)
        
        with patch("app.services.ai_assistant_service.init_chat_model") as mock_init:
            mock_model = AsyncMock()
            
            # Simulate multiple tool calls in response
            mock_model.ainvoke = AsyncMock(return_value=AIMessage(
                content="Analyzing your asset with fingerprint and value data...",
                tool_calls=[
                    {
                        "id": "call_1",
                        "name": "lookup_fingerprint",
                        "args": {"asset_id": "test-asset-123"}
                    },
                    {
                        "id": "call_2",
                        "name": "query_analytics",
                        "args": {"asset_id": "test-asset-123"}
                    }
                ]
            ))
            mock_model.bind_tools = MagicMock(return_value=mock_model)
            mock_init.return_value = mock_model
            
            service = AIAssistantService(
                settings=mock_settings,
                redis_client=mock_redis,
                db_client=mock_db
            )
            
            response = await service.send_message(
                user_id="test-user",
                message="Show me the fingerprint and value of asset test-asset-123",
                conversation_id="conv-multi-tool"
            )
            
            assert response is not None


# =============================================================================
# CONVERSATION FEATURE TESTS
# =============================================================================


class TestConversationFeatures:
    """Tests for advanced conversation features."""
    
    @pytest.mark.asyncio
    async def test_conversation_summarization(
        self,
        mock_settings: Settings,
        mock_redis: AsyncMock,
        mock_db: AsyncMock
    ):
        """Test long conversation handling."""
        # Create a long conversation history
        long_history = [
            {"role": "user", "content": f"Message {i}"}
            for i in range(50)
        ]
        
        mock_redis.get_json = AsyncMock(return_value=long_history)
        
        with patch("app.services.ai_assistant_service.init_chat_model") as mock_init:
            mock_model = AsyncMock()
            mock_model.ainvoke = AsyncMock(return_value=AIMessage(
                content="Summary response for long conversation"
            ))
            mock_model.bind_tools = MagicMock(return_value=mock_model)
            mock_init.return_value = mock_model
            
            service = AIAssistantService(
                settings=mock_settings,
                redis_client=mock_redis,
                db_client=mock_db
            )
            
            # Should handle long history gracefully (truncate/summarize)
            response = await service.send_message(
                user_id="test-user",
                message="Continue the conversation",
                conversation_id="conv-long"
            )
            
            assert response is not None
    
    @pytest.mark.asyncio
    async def test_conversation_context_limit(self):
        """Test context window management."""
        # Typical context limits
        max_context_tokens = 8000  # Example limit
        
        # Long message that might exceed context
        long_message = "A" * 50000  # 50k characters
        
        # Service should handle this gracefully
        truncated = long_message[:max_context_tokens * 4]  # ~4 chars per token
        assert len(truncated) <= max_context_tokens * 4
    
    @pytest.mark.asyncio
    async def test_conversation_reset(
        self,
        mock_settings: Settings,
        mock_redis: AsyncMock,
        mock_db: AsyncMock
    ):
        """Test clearing conversation history."""
        with patch("app.services.ai_assistant_service.init_chat_model") as mock_init:
            mock_model = AsyncMock()
            mock_model.ainvoke = AsyncMock(return_value=AIMessage(
                content="Starting fresh conversation"
            ))
            mock_model.bind_tools = MagicMock(return_value=mock_model)
            mock_init.return_value = mock_model
            
            service = AIAssistantService(
                settings=mock_settings,
                redis_client=mock_redis,
                db_client=mock_db
            )
            
            # Reset conversation
            if hasattr(service, "reset_conversation"):
                await service.reset_conversation(
                    user_id="test-user",
                    conversation_id="conv-reset"
                )
                mock_redis.delete.assert_called()
            else:
                # Alternative: just verify redis delete capability
                await mock_redis.delete("conversation:test-user:conv-reset")
                mock_redis.delete.assert_called()
    
    @pytest.mark.asyncio
    async def test_conversation_isolation(
        self,
        mock_settings: Settings,
        mock_redis: AsyncMock,
        mock_db: AsyncMock
    ):
        """Verify different users have separate contexts."""
        user1_context = [{"role": "user", "content": "User 1 message"}]
        user2_context = [{"role": "user", "content": "User 2 message"}]
        
        context_store = {}
        
        async def get_context(key):
            return context_store.get(key)
        
        async def set_context(key, value, ttl=None):
            context_store[key] = value
            return True
        
        mock_redis.get_json = AsyncMock(side_effect=get_context)
        mock_redis.set_json = AsyncMock(side_effect=set_context)
        
        with patch("app.services.ai_assistant_service.init_chat_model") as mock_init:
            mock_model = AsyncMock()
            mock_model.ainvoke = AsyncMock(return_value=AIMessage(
                content="Response to user"
            ))
            mock_model.bind_tools = MagicMock(return_value=mock_model)
            mock_init.return_value = mock_model
            
            service = AIAssistantService(
                settings=mock_settings,
                redis_client=mock_redis,
                db_client=mock_db
            )
            
            # User 1 sends message
            await service.send_message(
                user_id="user-1",
                message="User 1 message",
                conversation_id="conv-isolated"
            )
            
            # User 2 sends message
            await service.send_message(
                user_id="user-2",
                message="User 2 message",
                conversation_id="conv-isolated"
            )
            
            # Contexts should be stored separately
            # Keys should include user_id to ensure isolation
            assert len(context_store) >= 1


# =============================================================================
# PERFORMANCE TESTS
# =============================================================================


class TestPerformance:
    """Performance tests for AI assistant operations."""
    
    @pytest.mark.asyncio
    async def test_response_time_without_tools(
        self,
        mock_settings: Settings,
        mock_redis: AsyncMock,
        mock_db: AsyncMock
    ):
        """Verify <2s for simple queries without tool calls."""
        with patch("app.services.ai_assistant_service.init_chat_model") as mock_init:
            mock_model = AsyncMock()
            
            async def fast_response(*args, **kwargs):
                await asyncio.sleep(0.1)  # Simulate quick API response
                return AIMessage(content="Quick response")
            
            mock_model.ainvoke = AsyncMock(side_effect=fast_response)
            mock_model.bind_tools = MagicMock(return_value=mock_model)
            mock_init.return_value = mock_model
            
            service = AIAssistantService(
                settings=mock_settings,
                redis_client=mock_redis,
                db_client=mock_db
            )
            
            start_time = time.time()
            
            response = await service.send_message(
                user_id="test-user",
                message="Simple question",
                conversation_id="conv-perf-simple"
            )
            
            elapsed = time.time() - start_time
            
            # Should complete in under 2 seconds
            assert elapsed < 2.0
            assert response is not None
    
    @pytest.mark.asyncio
    async def test_response_time_with_tools(
        self,
        mock_settings: Settings,
        mock_redis: AsyncMock,
        mock_db: AsyncMock,
        test_fingerprint_data: Dict[str, Any]
    ):
        """Verify <5s with tool calls."""
        fingerprints_collection = mock_db.get_fingerprints_collection.return_value
        fingerprints_collection.find_one = AsyncMock(return_value=test_fingerprint_data)
        
        with patch("app.services.ai_assistant_service.init_chat_model") as mock_init:
            mock_model = AsyncMock()
            
            async def tool_response(*args, **kwargs):
                await asyncio.sleep(0.2)  # Simulate API call with tool
                return AIMessage(
                    content="Response with tool data",
                    tool_calls=[{
                        "id": "call_perf",
                        "name": "lookup_fingerprint",
                        "args": {"asset_id": "test-asset"}
                    }]
                )
            
            mock_model.ainvoke = AsyncMock(side_effect=tool_response)
            mock_model.bind_tools = MagicMock(return_value=mock_model)
            mock_init.return_value = mock_model
            
            service = AIAssistantService(
                settings=mock_settings,
                redis_client=mock_redis,
                db_client=mock_db
            )
            
            start_time = time.time()
            
            response = await service.send_message(
                user_id="test-user",
                message="Query with tool",
                conversation_id="conv-perf-tool"
            )
            
            elapsed = time.time() - start_time
            
            # Should complete in under 5 seconds even with tools
            assert elapsed < 5.0
            assert response is not None
    
    @pytest.mark.asyncio
    async def test_concurrent_conversations(
        self,
        mock_settings: Settings,
        mock_redis: AsyncMock,
        mock_db: AsyncMock
    ):
        """Test multiple users simultaneously."""
        with patch("app.services.ai_assistant_service.init_chat_model") as mock_init:
            mock_model = AsyncMock()
            
            async def concurrent_response(*args, **kwargs):
                await asyncio.sleep(0.05)  # Small delay to simulate processing
                return AIMessage(content="Concurrent response")
            
            mock_model.ainvoke = AsyncMock(side_effect=concurrent_response)
            mock_model.bind_tools = MagicMock(return_value=mock_model)
            mock_init.return_value = mock_model
            
            service = AIAssistantService(
                settings=mock_settings,
                redis_client=mock_redis,
                db_client=mock_db
            )
            
            # Create concurrent tasks for multiple users
            async def user_conversation(user_id: str, conv_id: str):
                return await service.send_message(
                    user_id=user_id,
                    message=f"Message from {user_id}",
                    conversation_id=conv_id
                )
            
            num_concurrent = 5
            tasks = [
                user_conversation(f"user-{i}", f"conv-{i}")
                for i in range(num_concurrent)
            ]
            
            start_time = time.time()
            results = await asyncio.gather(*tasks)
            elapsed = time.time() - start_time
            
            # All should complete
            assert len(results) == num_concurrent
            assert all(r is not None for r in results)
            
            # Should handle concurrency efficiently
            # With parallel execution, should be much faster than sequential
            # (5 * 0.05s = 0.25s sequential, but concurrent should be ~0.1s)
            assert elapsed < 2.0  # Allow for some overhead
    
    @pytest.mark.asyncio
    async def test_context_retrieval_performance(
        self,
        mock_settings: Settings,
        mock_redis: AsyncMock,
        mock_db: AsyncMock
    ):
        """Test Redis context retrieval is fast."""
        # Large conversation context
        large_context = [
            {"role": "user" if i % 2 == 0 else "assistant", "content": f"Message {i}"}
            for i in range(100)
        ]
        
        async def fast_redis_get(key):
            await asyncio.sleep(0.01)  # Simulate fast Redis lookup
            return large_context
        
        mock_redis.get_json = AsyncMock(side_effect=fast_redis_get)
        
        with patch("app.services.ai_assistant_service.init_chat_model") as mock_init:
            mock_model = AsyncMock()
            mock_model.ainvoke = AsyncMock(return_value=AIMessage(content="Response"))
            mock_model.bind_tools = MagicMock(return_value=mock_model)
            mock_init.return_value = mock_model
            
            service = AIAssistantService(
                settings=mock_settings,
                redis_client=mock_redis,
                db_client=mock_db
            )
            
            start_time = time.time()
            
            await service.send_message(
                user_id="test-user",
                message="Message with context",
                conversation_id="conv-perf-context"
            )
            
            elapsed = time.time() - start_time
            
            # Context retrieval should not add significant latency
            assert elapsed < 1.0
    
    @pytest.mark.asyncio
    async def test_streaming_performance(
        self,
        mock_settings: Settings,
        mock_redis: AsyncMock,
        mock_db: AsyncMock
    ):
        """Test streaming response delivery is efficient."""
        with patch("app.services.ai_assistant_service.init_chat_model") as mock_init:
            mock_model = AsyncMock()
            
            # Simulate streaming 20 tokens
            tokens = [f"token{i} " for i in range(20)]
            
            async def fast_stream(*args, **kwargs):
                for token in tokens:
                    await asyncio.sleep(0.01)  # Small delay per token
                    mock_chunk = MagicMock()
                    mock_chunk.content = token
                    yield mock_chunk
            
            mock_model.astream = fast_stream
            mock_model.bind_tools = MagicMock(return_value=mock_model)
            mock_init.return_value = mock_model
            
            service = AIAssistantService(
                settings=mock_settings,
                redis_client=mock_redis,
                db_client=mock_db
            )
            
            start_time = time.time()
            first_chunk_time = None
            chunks_received = []
            
            async for chunk in service.send_message_stream(
                user_id="test-user",
                message="Stream performance test",
                conversation_id="conv-perf-stream"
            ):
                if first_chunk_time is None:
                    first_chunk_time = time.time() - start_time
                chunks_received.append(chunk)
            
            total_time = time.time() - start_time
            
            # First chunk should arrive quickly (time-to-first-byte)
            if first_chunk_time is not None:
                assert first_chunk_time < 0.5
            
            # All tokens should be received
            assert len(chunks_received) == len(tokens)
            
            # Total streaming should complete in reasonable time
            assert total_time < 2.0


# =============================================================================
# ADDITIONAL EDGE CASE TESTS
# =============================================================================


class TestEdgeCases:
    """Tests for edge cases and boundary conditions."""
    
    @pytest.mark.asyncio
    async def test_empty_message_handling(
        self,
        mock_settings: Settings,
        mock_redis: AsyncMock,
        mock_db: AsyncMock
    ):
        """Test handling of empty messages."""
        with patch("app.services.ai_assistant_service.init_chat_model") as mock_init:
            mock_model = AsyncMock()
            mock_model.ainvoke = AsyncMock(return_value=AIMessage(
                content="Please provide a message."
            ))
            mock_model.bind_tools = MagicMock(return_value=mock_model)
            mock_init.return_value = mock_model
            
            service = AIAssistantService(
                settings=mock_settings,
                redis_client=mock_redis,
                db_client=mock_db
            )
            
            # Empty string
            try:
                response = await service.send_message(
                    user_id="test-user",
                    message="",
                    conversation_id="conv-empty"
                )
                # Should handle gracefully
                assert response is not None or response is None
            except ValueError:
                # Validation error is also acceptable
                pass
    
    @pytest.mark.asyncio
    async def test_special_characters_in_message(
        self,
        mock_settings: Settings,
        mock_redis: AsyncMock,
        mock_db: AsyncMock
    ):
        """Test handling of special characters."""
        special_message = "Hello! ä½ å¥½! Ù…Ø±Ø­Ø¨Ø§! ÐŸÑ€Ð¸Ð²ÐµÑ‚! ðŸŽ‰ <script>test</script>"
        
        with patch("app.services.ai_assistant_service.init_chat_model") as mock_init:
            mock_model = AsyncMock()
            mock_model.ainvoke = AsyncMock(return_value=AIMessage(
                content="Received your multilingual message!"
            ))
            mock_model.bind_tools = MagicMock(return_value=mock_model)
            mock_init.return_value = mock_model
            
            service = AIAssistantService(
                settings=mock_settings,
                redis_client=mock_redis,
                db_client=mock_db
            )
            
            response = await service.send_message(
                user_id="test-user",
                message=special_message,
                conversation_id="conv-special"
            )
            
            assert response is not None
    
    @pytest.mark.asyncio
    async def test_very_long_message(
        self,
        mock_settings: Settings,
        mock_redis: AsyncMock,
        mock_db: AsyncMock
    ):
        """Test handling of very long messages."""
        long_message = "A" * 10000  # 10k characters
        
        with patch("app.services.ai_assistant_service.init_chat_model") as mock_init:
            mock_model = AsyncMock()
            mock_model.ainvoke = AsyncMock(return_value=AIMessage(
                content="Processed your long message."
            ))
            mock_model.bind_tools = MagicMock(return_value=mock_model)
            mock_init.return_value = mock_model
            
            service = AIAssistantService(
                settings=mock_settings,
                redis_client=mock_redis,
                db_client=mock_db
            )
            
            response = await service.send_message(
                user_id="test-user",
                message=long_message,
                conversation_id="conv-long-msg"
            )
            
            # Should handle or truncate gracefully
            assert response is not None
    
    @pytest.mark.asyncio
    async def test_redis_connection_failure(
        self,
        mock_settings: Settings,
        mock_db: AsyncMock
    ):
        """Test behavior when Redis is unavailable."""
        failing_redis = AsyncMock(spec=RedisClient)
        failing_redis.get_json = AsyncMock(
            side_effect=Exception("Redis connection refused")
        )
        failing_redis.set_json = AsyncMock(
            side_effect=Exception("Redis connection refused")
        )
        
        with patch("app.services.ai_assistant_service.init_chat_model") as mock_init:
            mock_model = AsyncMock()
            mock_model.ainvoke = AsyncMock(return_value=AIMessage(
                content="Response without cache"
            ))
            mock_model.bind_tools = MagicMock(return_value=mock_model)
            mock_init.return_value = mock_model
            
            service = AIAssistantService(
                settings=mock_settings,
                redis_client=failing_redis,
                db_client=mock_db
            )
            
            # Should still work, just without context persistence
            try:
                response = await service.send_message(
                    user_id="test-user",
                    message="Test without Redis",
                    conversation_id="conv-no-redis"
                )
                # Response should still be generated
                assert response is not None
            except Exception as e:
                # Or gracefully handle the error
                assert "Redis" in str(e) or "connection" in str(e).lower()
    
    @pytest.mark.asyncio
    async def test_database_connection_failure(
        self,
        mock_settings: Settings,
        mock_redis: AsyncMock
    ):
        """Test behavior when MongoDB is unavailable for tool calls."""
        failing_db = AsyncMock(spec=DatabaseClient)
        failing_db.get_fingerprints_collection = MagicMock(
            side_effect=Exception("MongoDB connection refused")
        )
        
        with patch("app.services.ai_assistant_service.init_chat_model") as mock_init:
            mock_model = AsyncMock()
            mock_model.ainvoke = AsyncMock(return_value=AIMessage(
                content="Unable to access database",
                tool_calls=[{
                    "id": "call_fail",
                    "name": "lookup_fingerprint",
                    "args": {"asset_id": "test"}
                }]
            ))
            mock_model.bind_tools = MagicMock(return_value=mock_model)
            mock_init.return_value = mock_model
            
            service = AIAssistantService(
                settings=mock_settings,
                redis_client=mock_redis,
                db_client=failing_db
            )
            
            # Should handle database failure gracefully
            try:
                response = await service.send_message(
                    user_id="test-user",
                    message="Get my fingerprint",
                    conversation_id="conv-no-db"
                )
                # May respond with error message
                assert response is not None
            except Exception as e:
                # Or raise appropriate exception
                assert "MongoDB" in str(e) or "connection" in str(e).lower()
    
    @pytest.mark.asyncio
    async def test_null_conversation_id(
        self,
        mock_settings: Settings,
        mock_redis: AsyncMock,
        mock_db: AsyncMock
    ):
        """Test handling when conversation_id is None."""
        with patch("app.services.ai_assistant_service.init_chat_model") as mock_init:
            mock_model = AsyncMock()
            mock_model.ainvoke = AsyncMock(return_value=AIMessage(
                content="Response with generated conversation ID"
            ))
            mock_model.bind_tools = MagicMock(return_value=mock_model)
            mock_init.return_value = mock_model
            
            service = AIAssistantService(
                settings=mock_settings,
                redis_client=mock_redis,
                db_client=mock_db
            )
            
            # conversation_id=None should generate a new one
            response = await service.send_message(
                user_id="test-user",
                message="Message without conversation ID",
                conversation_id=None
            )
            
            assert response is not None


# =============================================================================
# MODEL CONFIGURATION TESTS
# =============================================================================


class TestModelConfiguration:
    """Tests for model configuration and settings."""
    
    def test_settings_contains_required_fields(self, mock_settings: Settings):
        """Verify all required settings fields are present."""
        assert hasattr(mock_settings, "openai_api_key")
        assert hasattr(mock_settings, "anthropic_api_key")
        assert hasattr(mock_settings, "google_api_key")
        assert hasattr(mock_settings, "default_ai_provider")
        assert hasattr(mock_settings, "default_ai_model")
        assert hasattr(mock_settings, "redis_url")
        assert hasattr(mock_settings, "mongodb_uri")
    
    def test_settings_api_keys_present(self, mock_settings: Settings):
        """Verify API keys are configured."""
        # At least one API key should be present for testing
        has_api_key = (
            mock_settings.openai_api_key is not None or
            mock_settings.anthropic_api_key is not None or
            mock_settings.google_api_key is not None
        )
        assert has_api_key
    
    def test_default_provider_valid(self, mock_settings: Settings):
        """Verify default provider is a valid option."""
        valid_providers = ["openai", "anthropic", "google", "local"]
        assert mock_settings.default_ai_provider in valid_providers
    
    @pytest.mark.asyncio
    async def test_model_initialization_with_all_providers(
        self,
        mock_settings: Settings,
        mock_redis: AsyncMock,
        mock_db: AsyncMock
    ):
        """Test initialization succeeds with various provider configs."""
        providers = [
            ("openai", "gpt-4"),
            ("anthropic", "claude-3-5-sonnet"),
            ("google", "gemini-2.0-flash"),
        ]
        
        for provider, model in providers:
            mock_settings.default_ai_provider = provider
            mock_settings.default_ai_model = model
            
            with patch("app.services.ai_assistant_service.init_chat_model") as mock_init:
                mock_model = AsyncMock()
                mock_model.ainvoke = AsyncMock(return_value=AIMessage(
                    content=f"Response from {provider}"
                ))
                mock_model.bind_tools = MagicMock(return_value=mock_model)
                mock_init.return_value = mock_model
                
                service = AIAssistantService(
                    settings=mock_settings,
                    redis_client=mock_redis,
                    db_client=mock_db
                )
                
                assert service is not None


